{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d23b88-90a0-4058-9b8f-7092d80fe6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skfda\n",
    "\n",
    "from skfda.preprocessing.dim_reduction import FPCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "path = './dataset/Electricity_dataset.csv'\n",
    "df =  pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017c20ef-2663-471e-b735-f35deccfca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62538/1782554617.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = df.groupby('unique_id').apply(lambda group: group.iloc[:-24 * days]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "days = 73\n",
    "p = 1\n",
    "n_components = 5\n",
    "\n",
    "test_df = df.groupby('unique_id').tail(24 * days)\n",
    "train_df = df.groupby('unique_id').apply(lambda group: group.iloc[:-24 * days]).reset_index(drop=True)\n",
    "\n",
    "test_df = test_df.pivot(index=\"ds\", columns=\"unique_id\", values=\"y\").reset_index()\n",
    "train_df = train_df.pivot(index=\"ds\", columns=\"unique_id\", values=\"y\").reset_index()\n",
    "\n",
    "# order of the list: 'AP-AP', 'DOM-DOM', 'JC-JC', 'PN-PN', 'RTO-RTO'\n",
    "train_array = train_df.drop(columns='ds').T.values.reshape(5, -1,24)\n",
    "test_array = test_df.drop(columns='ds').T.values.reshape(5, -1,24)\n",
    "\n",
    "inps = np.concatenate((train_array[:, -1 * p:, :], test_array), axis = 1) #concat all inputs\n",
    "#inputs = np.array([inps[:, i: i + p,:] for i in range(inps.shape[1] - p)]) # divide them into pairs by p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcc9ca1-ba33-4c9d-b92e-4596802349c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_matrix = train_array  # n days Ã— 24 time points\n",
    "grid_points = np.linspace(0, 1, 24)  # 24 time points over [0,1]\n",
    "\n",
    "# Define labels for functional data objects\n",
    "labels = [\"ap\", \"dom\", \"jc\", \"pn\", \"rto\"]\n",
    "\n",
    "array_objects = {label: data_matrix[i] for i, label in enumerate(labels)}\n",
    "array_inputs = {label: inps[i] for i, label in enumerate(labels)}\n",
    "\n",
    "fd_objects = {label: skfda.FDataGrid(data_matrix[i], grid_points) for i, label in enumerate(labels)}\n",
    "fd_inputs = {label: skfda.FDataGrid(inps[i], grid_points) for i, label in enumerate(labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466ab8ce-860b-4798-93e4-c81e7cf3c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfda.representation.basis import BSplineBasis\n",
    "from skfda.preprocessing.smoothing import BasisSmoother\n",
    "\n",
    "\n",
    "def PCAVAR_fit_predict(train_fd, input_fd, n_components=5, p=1, steps=1):\n",
    "    \n",
    "    # Apply FPCA to extract empirical basis functions\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(train_fd)\n",
    "\n",
    "    # Transform the original data into PCA scores\n",
    "    scores = pca.transform(train_fd)\n",
    "    scores_df = pd.DataFrame(scores, columns=[f'PC{i+1}' for i in range(scores.shape[1])])\n",
    "\n",
    "    # Fit VAR(p) model\n",
    "    var_model = VAR(scores)\n",
    "    var_result = var_model.fit(maxlags=p)  # WITH intercept\n",
    "\n",
    "    # Convert inputs FD into PCA scores\n",
    "    input_scores = pca.transform(input_fd)      \n",
    "    input_scores_array = np.array([input_scores[i: i + p, :] for i in range(inps.shape[1] - p)])\n",
    "\n",
    "    preds = []\n",
    "    \n",
    "    for inputs in input_scores_array:\n",
    "\n",
    "        forecast = var_result.forecast(inputs, steps=steps)\n",
    "        reconstructed_fd = pca.inverse_transform(forecast)\n",
    "        \n",
    "        preds.append(reconstructed_fd)\n",
    "\n",
    "    return np.array(preds).squeeze(), pca\n",
    "\n",
    "\n",
    "def ARH_fit_predict(train_fd, input_fd, n_components=5, p=1, steps=1):\n",
    "    \n",
    "    basis = BSplineBasis(n_basis=12)  \n",
    "    smoother = BasisSmoother(basis)\n",
    "    fd_smooth = smoother.fit_transform(train_fd)\n",
    "    \n",
    "    fpca = FPCA(n_components=n_components)\n",
    "    fpca.fit(fd_smooth)\n",
    "\n",
    "    # Transform the original data into FPCA scores\n",
    "    scores = fpca.transform(fd_smooth)\n",
    "    scores_df = pd.DataFrame(scores, columns=[f'PC{i+1}' for i in range(scores.shape[1])])\n",
    "\n",
    "    var_model = VAR(scores)\n",
    "    var_result = var_model.fit(maxlags=p)  # WITH intercept\n",
    "\n",
    "    # Convert inputs FD into FPCA scores\n",
    "    input_scores = fpca.transform(input_fd)  \n",
    "    input_scores_array = np.array([input_scores[i: i + p,:] for i in range(inps.shape[1] - p)])\n",
    "    \n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for inputs in input_scores_array:\n",
    "    \n",
    "        forecast = var_result.forecast(inputs, steps=steps)\n",
    "        reconstructed_fd = fpca.inverse_transform(forecast)\n",
    "        \n",
    "        preds.append(reconstructed_fd.data_matrix[0])\n",
    "\n",
    "    return np.array(preds).squeeze(), fpca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a2bd74-74be-44d7-8c5c-3d56ad0b8bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARH model predictions\n",
    "ARH_preds_ap, fpca_ap     = ARH_fit_predict(fd_objects[\"ap\"], fd_inputs[\"ap\"], n_components=n_components, p=p, steps=1)\n",
    "ARH_preds_dom, fpca_dom   = ARH_fit_predict(fd_objects[\"dom\"], fd_inputs[\"dom\"], n_components=n_components, p=p, steps=1)\n",
    "ARH_preds_jc, fpca_jc     = ARH_fit_predict(fd_objects[\"jc\"], fd_inputs[\"jc\"], n_components=n_components, p=p, steps=1)\n",
    "ARH_preds_pn, fpca_pn     = ARH_fit_predict(fd_objects[\"pn\"], fd_inputs[\"pn\"], n_components=n_components, p=p, steps=1)\n",
    "ARH_preds_rto, fpca_rto   = ARH_fit_predict(fd_objects[\"rto\"], fd_inputs[\"rto\"], n_components=n_components, p=p, steps=1)\n",
    "\n",
    "# PCA-VAR model predictions\n",
    "PCAVAR_preds_ap, pca_ap     = PCAVAR_fit_predict(array_objects[\"ap\"], array_inputs[\"ap\"], n_components=n_components, p=p, steps=1)\n",
    "PCAVAR_preds_dom, pca_dom   = PCAVAR_fit_predict(array_objects[\"dom\"], array_inputs[\"dom\"], n_components=n_components, p=p, steps=1)\n",
    "PCAVAR_preds_jc, pca_jc     = PCAVAR_fit_predict(array_objects[\"jc\"], array_inputs[\"jc\"], n_components=n_components, p=p, steps=1)\n",
    "PCAVAR_preds_pn, pca_pn     = PCAVAR_fit_predict(array_objects[\"pn\"], array_inputs[\"pn\"], n_components=n_components, p=p, steps=1)\n",
    "PCAVAR_preds_rto, pca_rto   = PCAVAR_fit_predict(array_objects[\"rto\"], array_inputs[\"rto\"], n_components=n_components, p=p, steps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5271e11c-add9-432b-a57e-c70bfd430d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979021069439495\n",
      "0.9976546520274417\n",
      "0.9973385982611992\n",
      "0.9956178377360317\n",
      "0.9984475285312647\n",
      "\n",
      " 0.9971488485915895\n",
      "0.9969960086179049\n",
      "0.996307120215542\n",
      "0.9933916456646801\n",
      "0.9980166526966494\n"
     ]
    }
   ],
   "source": [
    "print(fpca_ap.explained_variance_ratio_.sum())\n",
    "print(fpca_dom.explained_variance_ratio_.sum())\n",
    "print(fpca_jc.explained_variance_ratio_.sum())\n",
    "print(fpca_pn.explained_variance_ratio_.sum())\n",
    "print(fpca_rto.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "print(\"\\n\", pca_ap.explained_variance_ratio_.sum())\n",
    "print(pca_dom.explained_variance_ratio_.sum())\n",
    "print(pca_jc.explained_variance_ratio_.sum())\n",
    "print(pca_pn.explained_variance_ratio_.sum())\n",
    "print(pca_rto.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cd2a05-777c-47e7-a2af-2f19e5719c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_errors(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    return {\"MAE\": mae, \"MSE\": mse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9fb96e9-3f42-4e72-a73b-06047fe98fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARH metrics:\n",
      "\n",
      "{'MAE': 242.72823471639933, 'MSE': 116187.86237483878}\n",
      "{'MAE': 622.7588232875279, 'MSE': 684669.0324304459}\n",
      "{'MAE': 219.67997002952526, 'MSE': 112751.31774540889}\n",
      "{'MAE': 79.24471565831568, 'MSE': 11460.156374459657}\n",
      "{'MAE': 3630.277702128358, 'MSE': 22705331.380642965}\n",
      "\n",
      "PCA + VAR metrics:\n",
      "\n",
      "{'MAE': 240.99230654137767, 'MSE': 116297.62391418676}\n",
      "{'MAE': 612.0931060470923, 'MSE': 667872.3201745803}\n",
      "{'MAE': 217.91814946264816, 'MSE': 112294.48098146821}\n",
      "{'MAE': 78.72829089716795, 'MSE': 11430.801145007634}\n",
      "{'MAE': 3598.3232506665195, 'MSE': 22660110.583822284}\n"
     ]
    }
   ],
   "source": [
    "# order of the list: 'AP-AP', 'DOM-DOM', 'JC-JC', 'PN-PN', 'RTO-RTO'\n",
    "print(\"ARH metrics:\\n\")\n",
    "print(calculate_errors(test_array[0], ARH_preds_ap))\n",
    "print(calculate_errors(test_array[1], ARH_preds_dom))\n",
    "print(calculate_errors(test_array[2], ARH_preds_jc))\n",
    "print(calculate_errors(test_array[3], ARH_preds_pn))\n",
    "print(calculate_errors(test_array[4], ARH_preds_rto))\n",
    "\n",
    "\n",
    "# order of the list: 'AP-AP', 'DOM-DOM', 'JC-JC', 'PN-PN', 'RTO-RTO'\n",
    "print(\"\\nPCA + VAR metrics:\\n\")\n",
    "print(calculate_errors(test_array[0], PCAVAR_preds_ap))\n",
    "print(calculate_errors(test_array[1], PCAVAR_preds_dom))\n",
    "print(calculate_errors(test_array[2], PCAVAR_preds_jc))\n",
    "print(calculate_errors(test_array[3], PCAVAR_preds_pn))\n",
    "print(calculate_errors(test_array[4], PCAVAR_preds_rto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4fe96e-1b05-4771-988f-08e6e71c3456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "arh_results = pd.DataFrame({\n",
    "    \"AP-AP\": ARH_preds_ap.ravel(),\n",
    "    \"DOM-DOM\": ARH_preds_dom.ravel(),\n",
    "    \"JC-JC\": ARH_preds_jc.ravel(),\n",
    "    \"PN-PN\": ARH_preds_pn.ravel(),\n",
    "    \"RTO-RTO\": ARH_preds_rto.ravel()\n",
    "})\n",
    "\n",
    "pca_results = pd.DataFrame({\n",
    "    \"AP-AP\": PCAVAR_preds_ap.ravel(),\n",
    "    \"DOM-DOM\": PCAVAR_preds_dom.ravel(),\n",
    "    \"JC-JC\": PCAVAR_preds_jc.ravel(),\n",
    "    \"PN-PN\": PCAVAR_preds_pn.ravel(),\n",
    "    \"RTO-RTO\": PCAVAR_preds_rto.ravel()\n",
    "})\n",
    "\n",
    "arh_results.to_csv(\"preds/ARH(1) predictions/arh1_all_73days.csv\", index=False)\n",
    "pca_results.to_csv(\"preds/PCA(1) predictions/pca_all_73days.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5fa0a-a271-4426-81f9-16a8034f6019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb5332-0b6f-47a7-9d35-4d730fb61082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch(FDA)",
   "language": "python",
   "name": "pytorch_fda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
