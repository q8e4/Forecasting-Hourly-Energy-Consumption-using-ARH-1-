{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq nixtla\n",
        "!pip install -q dask[dataframe]\n",
        "!pip install -q neuralforecast"
      ],
      "metadata": {
        "id": "0lcK0SQDUwIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvs2f-NkFjw6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from nixtla import NixtlaClient\n",
        "\n",
        "from utilsforecast.losses import mae, smape, mse\n",
        "from utilsforecast.evaluation import evaluate\n",
        "\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.models import NHITS, LSTM\n",
        "from neuralforecast.losses.pytorch import DistributionLoss\n",
        "\n",
        "from utilsforecast.plotting import plot_series\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "nixtla_client = NixtlaClient(\n",
        "    # defaults to os.environ.get(\"NIXTLA_API_KEY\")\n",
        "    api_key = 'nixak-u0uuMKxJQLH7NljBpZRjckwKuENxptz6beRKSaVPvjPheR4P5H9J3Ju9rK47rGoN4qeUqlxgoqICfJ1O'\n",
        ")\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/refs/heads/main/datasets/pjm_in_zone.csv')\n",
        "df['ds'] = pd.to_datetime(df['ds'])\n",
        "\n",
        "\n",
        "df.groupby('unique_id').head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c3sqM3O1Ba5"
      },
      "outputs": [],
      "source": [
        "def generate_inputs(df, days=73):\n",
        "\n",
        "    test_df = df.groupby('unique_id').tail(24 * days)\n",
        "    train_df = df.groupby('unique_id').apply(lambda group: group.iloc[:-1 * (24 * days)]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "    #create list of 73 days true values for each unique_id\n",
        "    Y_df = [\n",
        "    test_df.groupby('unique_id', group_keys=False).apply(lambda group: group.iloc[i:i+24]).reset_index(drop=True)\n",
        "    for i in range(0, 24 * days, 24)\n",
        "    ]\n",
        "\n",
        "    p = 1\n",
        "\n",
        "    #create paired inputs\n",
        "    inputs_df = [Y_df[i] for i in range(len(Y_df) - p)]\n",
        "\n",
        "    inputs_df.insert(0, train_df.groupby('unique_id', group_keys=False).apply(lambda group: group.iloc[-24:]))\n",
        "\n",
        "\n",
        "    return Y_df, inputs_df, train_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JClIrmRi-0w"
      },
      "outputs": [],
      "source": [
        "Y_df, inputs_df, train_df, test_df = generate_inputs(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFM0m--mCgi"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymP5u-mn9p-z"
      },
      "outputs": [],
      "source": [
        "models = [NHITS(\n",
        "                h=24,\n",
        "                input_size=24,\n",
        "                scaler_type='robust',\n",
        "                batch_size=16,\n",
        "                valid_batch_size=8,\n",
        "                max_steps=3000\n",
        "          ),\n",
        "\n",
        "          LSTM(\n",
        "              h=24,\n",
        "              input_size=24,\n",
        "              scaler_type='robust',\n",
        "              encoder_n_layers=1,\n",
        "              encoder_hidden_size=64,\n",
        "              context_size=128,\n",
        "              decoder_hidden_size=128,\n",
        "              decoder_layers=5,\n",
        "              learning_rate=1e-4,\n",
        "              encoder_dropout=0.1,\n",
        "              max_steps=3000\n",
        "          )\n",
        "]\n",
        "\n",
        "nf = NeuralForecast(models=models, freq='h')\n",
        "nf.fit(df=train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i0HBTfTaorX"
      },
      "outputs": [],
      "source": [
        "nf.save(\n",
        "    path='./checkpoint/models/',\n",
        "    model_index=None,\n",
        "    overwrite=True,\n",
        "    save_dataset=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euDyQaRVi78j"
      },
      "outputs": [],
      "source": [
        "def funcs_test(inputs_df, Y_df):\n",
        "\n",
        "  preds = [nf.predict(inputs_df[i]) for i in range(len(Y_df))]\n",
        "  y_preds_df = [pd.merge(Y_df[i], preds[i], 'left', ['unique_id', 'ds']) for i in range(len(Y_df))]\n",
        "\n",
        "  evals = []\n",
        "\n",
        "  for i in range(len(y_preds_df)):\n",
        "      evaluation = evaluate(\n",
        "                  y_preds_df[i],\n",
        "                  metrics=[mse, mae, smape],\n",
        "                  models=['NHITS', 'LSTM'],\n",
        "                  target_col='y',\n",
        "                  id_col='unique_id'\n",
        "                )\n",
        "\n",
        "      evals.append(evaluation)\n",
        "\n",
        "  return evals, preds, y_preds_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvdv7BAp_YAT"
      },
      "outputs": [],
      "source": [
        "evaluations, preds, y_preds_df = funcs_test(inputs_df, Y_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdBqk81ESCa7"
      },
      "outputs": [],
      "source": [
        "preds_concat= pd.concat(preds, ignore_index=True)\n",
        "Y_df_concat = pd.concat(Y_df, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkZmkzIbvrzF"
      },
      "source": [
        "#TimeGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGofBScquPCp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def TimegptForecast():\n",
        "  full_forecast = []\n",
        "  training_data = train_df.copy()\n",
        "\n",
        "  for i in range(0, 24 * 73, 24):\n",
        "\n",
        "      fcst_df = nixtla_client.forecast(\n",
        "          df=training_data,\n",
        "          h=24,\n",
        "          finetune_steps=10,\n",
        "          finetune_loss='mae',\n",
        "          model='timegpt-1',\n",
        "          time_col='ds',\n",
        "          target_col='y',\n",
        "          id_col='unique_id'\n",
        "      )\n",
        "\n",
        "      #1 day from train set + 1 day from test -> 2 days from test -> next 2 days from test\n",
        "      training_data = pd.concat([training_data, test_df.groupby('unique_id', group_keys=False).apply(lambda group: group.iloc[i:i+24])], ignore_index=True)\n",
        "\n",
        "      full_forecast.append(fcst_df)\n",
        "\n",
        "  return full_forecast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDyPNLpRYF4O"
      },
      "outputs": [],
      "source": [
        "forecasts = TimegptForecast()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Nq27Hfb3ix"
      },
      "outputs": [],
      "source": [
        "forecasts = pd.concat(forecasts, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUHdsNNy0Zn8"
      },
      "outputs": [],
      "source": [
        "all_res = pd.merge(preds_concat, forecasts, 'left', ['unique_id', 'ds'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAohYMgs4KUg"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(64, 32))\n",
        "\n",
        "\n",
        "nixtla_client.plot(Y_df_concat.groupby('unique_id').head(876),\n",
        "                   all_res.groupby('unique_id').head(876),\n",
        "                   models=['TimeGPT', 'LSTM', 'NHITS'], time_col='ds',\n",
        "                   target_col='y', ax=axes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsNHXLTBzcEv"
      },
      "outputs": [],
      "source": [
        "Y_df_concat = pd.concat(Y_df, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f0DQYv7xCUm"
      },
      "outputs": [],
      "source": [
        "eval_df = pd.merge(Y_df_concat, all_res, 'left', ['unique_id', 'ds'])\n",
        "eval_df.to_csv('nixtla_preds.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByP3D7k_7qqa"
      },
      "outputs": [],
      "source": [
        "evaluation = evaluate(\n",
        "    eval_df,\n",
        "    metrics=[mse, mae, smape],\n",
        "    models=['NHITS', 'LSTM', 'TimeGPT'],\n",
        "    target_col='y',\n",
        "    id_col='unique_id'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', '{:.6f}'.format)\n",
        "evaluation.sort_values(['unique_id', 'metric']).groupby('unique_id', group_keys=False).head()"
      ],
      "metadata": {
        "id": "095tTG9UZS-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXDpXyD_0Ob8"
      },
      "outputs": [],
      "source": [
        "nhits_mean = evaluation.groupby('metric')['NHITS'].mean().apply(lambda x: f\"{x:.6f}\")\n",
        "timegpt_mean = evaluation.groupby('metric')['TimeGPT'].mean().apply(lambda x: f\"{x:.6f}\")\n",
        "lstm_mean = evaluation.groupby('metric')['LSTM'].mean().apply(lambda x: f\"{x:.6f}\")\n",
        "\n",
        "formatted_df = pd.DataFrame({\n",
        "    \"NHITS\": nhits_mean,\n",
        "    \"LSTM\": lstm_mean,\n",
        "    \"TimeGPT\": timegpt_mean,\n",
        "})\n",
        "\n",
        "formatted_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_res.to_csv(\"nixtla_preds.csv\")"
      ],
      "metadata": {
        "id": "yorNdiUTWj6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2XGH_joQZdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}